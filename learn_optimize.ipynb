{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from subprocess import run\n",
    "import shutil as st\n",
    "import argparse\n",
    "import main\n",
    "import sys\n",
    "import torch\n",
    "import msgpack as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Crystal Graph Convolutional Neural Networks')\n",
    "# parser.add_argument('data_options', metavar='OPTIONS', nargs='+',\n",
    "#                     help='dataset options, started with the path to root dir, '\n",
    "#                          'then other options')\n",
    "parser.add_argument('--task', choices=['regression', 'classification'],\n",
    "                    default='regression', help='complete a regression or '\n",
    "                                                   'classification task (default: regression)')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "parser.add_argument('-j', '--workers', default=0, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 0)')\n",
    "parser.add_argument('--epochs', default=30, type=int, metavar='N',\n",
    "                    help='number of total epochs to run (default: 30)')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate (default: '\n",
    "                                       '0.01)')\n",
    "parser.add_argument('--lr-milestones', default=[100], nargs='+', type=int,\n",
    "                    metavar='N', help='milestones for scheduler (default: '\n",
    "                                      '[100])')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=0, type=float,\n",
    "                    metavar='W', help='weight decay (default: 0)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "train_group = parser.add_mutually_exclusive_group()\n",
    "train_group.add_argument('--train-ratio', default=0.6, type=float, metavar='N',\n",
    "                    help='number of training data to be loaded (default none)')\n",
    "train_group.add_argument('--train-size', default=None, type=int, metavar='N',\n",
    "                         help='number of training data to be loaded (default none)')\n",
    "valid_group = parser.add_mutually_exclusive_group()\n",
    "valid_group.add_argument('--val-ratio', default=0.2, type=float, metavar='N',\n",
    "                    help='percentage of validation data to be loaded (default '\n",
    "                         '0.1)')\n",
    "valid_group.add_argument('--val-size', default=None, type=int, metavar='N',\n",
    "                         help='number of validation data to be loaded (default '\n",
    "                              '1000)')\n",
    "test_group = parser.add_mutually_exclusive_group()\n",
    "test_group.add_argument('--test-ratio', default=0.2, type=float, metavar='N',\n",
    "                    help='percentage of test data to be loaded (default 0.1)')\n",
    "test_group.add_argument('--test-size', default=None, type=int, metavar='N',\n",
    "                        help='number of test data to be loaded (default 1000)')\n",
    "\n",
    "parser.add_argument('--optim', default='SGD', type=str, metavar='SGD',\n",
    "                    help='choose an optimizer, SGD or Adam, (default: SGD)')\n",
    "parser.add_argument('--atom-fea-len', default=64, type=int, metavar='N',\n",
    "                    help='number of hidden atom features in conv layers')\n",
    "parser.add_argument('--h-fea-len', default=128, type=int, metavar='N',\n",
    "                    help='number of hidden features after pooling')\n",
    "parser.add_argument('--n-conv', default=3, type=int, metavar='N',\n",
    "                    help='number of conv layers')\n",
    "parser.add_argument('--n-h', default=1, type=int, metavar='N',\n",
    "                    help='number of hidden layers after pooling')\n",
    "args = parser.parse_args()\n",
    "args['data_options'] = './data/root/data/'\n",
    "args.cuda = not args.disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "if args.task == 'regression':\n",
    "    best_mae_error = 1e10\n",
    "else:\n",
    "    best_mae_error = 0.\n",
    "\n",
    "\n",
    "fields = [\n",
    "    \"energy_per_atom\",\n",
    "    \"formation_energy_per_atom\",\n",
    "    \"band_gap\",\n",
    "    \"efermi\",\n",
    "    # \"k_voigt\",\n",
    "    # \"k_reuss\",\n",
    "    # \"k_vrh\",\n",
    "    # \"g_voigt\",\n",
    "    # \"g_reuss\",\n",
    "    # \"g_vrh\",\n",
    "    \"homogeneous_poisson\",\n",
    "]\n",
    "\n",
    "reference_csv = {\n",
    "    \"mp-ids-3402.csv\": [\n",
    "        # \"k_voigt\",\n",
    "        # \"k_reuss\",\n",
    "        # \"k_vrh\",\n",
    "        # \"g_voigt\",\n",
    "        # \"g_reuss\",\n",
    "        # \"g_vrh\",\n",
    "        \"homogeneous_poisson\",\n",
    "    ],\n",
    "    \"mp-ids-27430.csv\": [\"band_gap\"],\n",
    "    \"mp-ids-46744.csv\": [\"energy_per_atom\", \"formation_energy_per_atom\", \"efermi\"],\n",
    "}\n",
    "\n",
    "def load_properties_from_bin(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        properties = mp.unpackb(f.read())\n",
    "        return properties\n",
    "    return None\n",
    "\n",
    "t2m_file = './data/root/data/t2m.bin'\n",
    "t2m = load_properties_from_bin(t2m_file)\n",
    "\n",
    "full_df = pd.read_csv(\"./scripts/non_ill_df.csv\",index_col=0)\n",
    "\n",
    "full_df = pd.DataFrame(load_properties_from_bin('./data/root/data/props.bin')).transpose()\n",
    "# print(full_df.head(10))\n",
    "\n",
    "for moduli in [\"k_voigt\", \"k_reuss\", \"k_vrh\", \"g_voigt\", \"g_reuss\", \"g_vrh\"]:\n",
    "    full_df[moduli] = np.log(full_df[moduli])\n",
    "# print(full_df.describe())\n",
    "def get_df_for_csv(csv:str):\n",
    "    global t2m, full_df\n",
    "\n",
    "    ids = pd.read_csv(\"./data/material-data/\" + csv)\n",
    "    ids = [list(ids)[0]]+list(ids.iloc[:, 0])\n",
    "    df = pd.DataFrame()\n",
    "    for t in ids:\n",
    "        m = t2m[t]\n",
    "        df.loc\n",
    "        df=pd.concat([df,full_df.loc[[m]]])\n",
    "    return df\n",
    "\n",
    "def set_property_to_ids(df: pd.DataFrame, prop: str):\n",
    "    part_df = df[prop].dropna()\n",
    "    part_df = part_df.groupby(part_df.index).first()\n",
    "    part_df.to_csv(\"./data/root/data/id_prop.csv\", index=True, header=False)\n",
    "\n",
    "all_params = {\n",
    "                # 'numprops':[2,3,10],\n",
    "              'n_conv':list(range(1,6)),\n",
    "              'atom_fea_len':[10,20,50,100,200],\n",
    "              'h_fea_len':[10,20,50,100,200],\n",
    "              'n_h':list(range(1,5)),\n",
    "            #   '':list(range(1,6)),\n",
    "            #   '':[np.exp(x) for x in [-6,-4,-2,0]],\n",
    "            #   '':[np.exp(x) for x in [-8,-6,-4,-2]],\n",
    "            #   '':[np.exp(x) for x in range(-8,-2)],\n",
    "            #   '':[0,0.1,0.2]\n",
    "            }\n",
    "reslist = list()\n",
    "maedict = dict()\n",
    "\n",
    "import skopt\n",
    "from skopt import space\n",
    "best_mae = dict()\n",
    "prop = 'band_gap'\n",
    "current_property = prop\n",
    "df = get_df_for_csv('mp-ids-27430.csv')\n",
    "print(df.describe())\n",
    "set_property_to_ids(df, prop)\n",
    "SPACE = [\n",
    "    space.Integer(1,6, name='n_conv', prior='uniform'),\n",
    "    space.Integer(10, 200, name='atom_fea_len',prior='uniform'),\n",
    "    space.Integer(10, 200, name='h_fea_len'),\n",
    "    space.Integer(1, 6, name='n_h'),]\n",
    "@skopt.utils.use_named_args(SPACE)\n",
    "def objective(**params):\n",
    "    tmp = {\n",
    "'n_conv':int(params['n_conv']),\n",
    "'atom_fea_len':int(params['atom_fea_len']),\n",
    "'h_fea_len':int(params['h_fea_len']),\n",
    "'n_h':int(params['n_h']),}\n",
    "    reslist.append((100,tmp))\n",
    "    with open(f\"opt_hyperparams_prop_{current_property}_log.json\", \"w\") as f:\n",
    "        json.dump(reslist, f)\n",
    "    \n",
    "    args.n_conv =params['n_conv']\n",
    "    args.atom_fea_len =params['atom_fea_len']\n",
    "    args.h_fea_len =params['h_fea_len']\n",
    "    args.n_h =params['n_h']\n",
    "    oom = False\n",
    "    try:\n",
    "        res =  main.main(args= args,torch_generator=1)\n",
    "        st.move(\"checkpoint.pth.tar\", \"./trained/\" + prop + \"_check.pth.tar\")\n",
    "        st.move(\"model_best.pth.tar\", \"./trained/\" + prop + \"_best.pth.tar\")\n",
    "        st.move(\"test_results.csv\", \"./trained/\" + prop + \"_results.csv\")\n",
    "    except RuntimeError:\n",
    "        oom = True\n",
    "        \n",
    "    if oom:\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        args.disable_cuda =True\n",
    "        args.cuda = not args.disable_cuda and torch.cuda.is_available()\n",
    "        # res =  main.main(args= args,torch_generator=1)\n",
    "        res = 1\n",
    "        # <- ~ big value\n",
    "        args.disable_cuda =False\n",
    "        args.cuda = not args.disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "    res=float(res)\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    reslist[-1] = ((res,tmp))\n",
    "    with open(f\"opt_hyperparams_prop_{current_property}_log.json\", \"w\") as f:\n",
    "        json.dump(reslist, f)\n",
    "    return res\n",
    "from skopt import BayesSearchCV\n",
    "results = skopt.gp_minimize(objective, SPACE, n_calls=20, n_initial_points=1,x0=[[i.high for i in SPACE]])\n",
    "with open(f\"opt_hyperparams_best_log.json\", \"w\") as f:\n",
    "    json.dump(best_mae, f)\n",
    "import skopt.plots as plots\n",
    "import matplotlib.pyplot as plt\n",
    "_ = plots.plot_objective(results,  sample_source='result', n_points=20)\n",
    "plt.savefig(\"fig.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1509f755d693feea69328e7bc671a76db594dddf9693d82a53ea384d1f791343"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
