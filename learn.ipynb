{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46744\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pymatgen.io.cif import CifWriter\n",
    "from mp_api.client import MPRester\n",
    "import pandas as pd\n",
    "import json\n",
    "import ormsgpack as mp\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "api_key = os.environ.get(\"MP_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ids\n",
    "ids = pd.read_csv(\"./data/material-data/mp-ids-46744.csv\")\n",
    "ids = [list(ids)[0]] + list(ids.iloc[:, 0])\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my venn diagram for two sets\n",
    "def venn(**kvarg):\n",
    "    subsets = []\n",
    "    set_labels = []\n",
    "    for k, v in kvarg.items():\n",
    "        subsets.append(set(v))\n",
    "        set_labels.append(k)\n",
    "    return venn2(subsets=subsets, set_labels=set_labels)\n",
    "\n",
    "\n",
    "# get duplicates set of duplicates\n",
    "def get_duplicates_list(a: list):\n",
    "    h = dict()\n",
    "    for x in a:\n",
    "        h.setdefault(x, 0)\n",
    "        h[x] += 1\n",
    "    repeated = list()\n",
    "    for k, v in h.items():\n",
    "        if v > 1:\n",
    "            repeated += [k for i in range(1, v)]\n",
    "    return repeated\n",
    "\n",
    "\n",
    "def get_duplicates_set(a: list):\n",
    "    return set(get_duplicates_list(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MPRester(api_key) as mpr:\n",
    "    # naive_docs = mpr.materials.search(material_ids=ids, fields=['material_id'])\n",
    "    # ValueError: List of material/molecule IDs provided is too long. Consider removing the ID filter to automatically pull data for all IDs and filter locally.\n",
    "    # fix via chunk loading with const:\n",
    "    # 10000\n",
    "    filter_const = 10000\n",
    "    naive_docs = [\n",
    "        d\n",
    "        for k in range(0, len(ids), filter_const)\n",
    "        for d in mpr.materials.search(\n",
    "            material_ids=ids[k : k + filter_const], fields=[\"material_id\"]\n",
    "        )\n",
    "    ]\n",
    "    depr_naive_docs = [\n",
    "        d\n",
    "        for k in range(0, len(ids), filter_const)\n",
    "        for d in mpr.materials.search(\n",
    "            material_ids=ids[k : k + filter_const],\n",
    "            fields=[\"material_id\"],\n",
    "            deprecated=True,\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_material_ids = [str(d.material_id) for d in naive_docs]\n",
    "naive_material_ids_repeated = get_duplicates_set(naive_material_ids)\n",
    "\n",
    "depr_naive_material_ids = [str(d.material_id) for d in depr_naive_docs]\n",
    "depr_naive_material_ids_repeated = get_duplicates_set(depr_naive_material_ids)\n",
    "venn(naive_material_ids=naive_material_ids,\n",
    "     depr_naive_material_ids=depr_naive_material_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn(naive_material_ids=naive_material_ids,\n",
    "     naive_material_ids_repeated=naive_material_ids_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn(depr_naive_material_ids=depr_naive_material_ids,\n",
    "     depr_naive_material_ids_repeated=depr_naive_material_ids_repeated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MPRester(api_key) as mpr:\n",
    "    docs = [\n",
    "        d\n",
    "        for k in range(0, len(ids), filter_const)\n",
    "        for d in mpr.materials.search(\n",
    "            task_ids=ids[k : k + filter_const], fields=[\"material_id\"]\n",
    "        )\n",
    "    ]\n",
    "    depr_docs = [\n",
    "        d\n",
    "        for k in range(0, len(ids), filter_const)\n",
    "        for d in mpr.materials.search(\n",
    "            task_ids=ids[k : k + filter_const], fields=[\"material_id\"], deprecated=True\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_ids = [str(d.material_id) for d in docs]\n",
    "material_ids_repeated = get_duplicates_set(material_ids)\n",
    "\n",
    "depr_material_ids = [str(d.material_id) for d in depr_docs]\n",
    "depr_material_ids_repeated = get_duplicates_set(depr_material_ids)\n",
    "\n",
    "venn(material_ids=material_ids,\n",
    "     depr_material_ids=depr_material_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn(material_ids=material_ids,\n",
    "     material_ids_repeated=material_ids_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn(depr_material_ids=depr_material_ids,\n",
    "     depr_material_ids_repeated=depr_material_ids_repeated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the complete set of material_ids it is possible to create a map between task_ids and material_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mids = list(set(material_ids).union(set(depr_material_ids)))\n",
    "mids = list(set(material_ids))\n",
    "depr_mids = list(set(depr_material_ids))\n",
    "with MPRester(api_key) as mpr:\n",
    "    docs_for_t2m = [\n",
    "        d\n",
    "        for k in range(0, len(all_mids), filter_const)\n",
    "        for d in mpr.materials.search(\n",
    "            material_ids=all_mids[k : k + filter_const],\n",
    "            fields=[\"material_id\", \"task_ids\"],\n",
    "        )\n",
    "    ]\n",
    "    depr_docs_for_t2m = [\n",
    "        d\n",
    "        for k in range(0, len(all_mids), filter_const)\n",
    "        for d in mpr.materials.search(\n",
    "            material_ids=all_mids[k : k + filter_const],\n",
    "            fields=[\"material_id\", \"task_ids\"],\n",
    "            deprecated=True,\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mids = [str(d.material_id) for d in docs_for_t2m]\n",
    "depr_mids = [str(d.material_id) for d in depr_docs_for_t2m]\n",
    "venn(mids=mids, depr_mids=depr_mids)\n",
    "# No venn intersection => mids are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtids = [(str(d.material_id), [str(x) for x in d.task_ids]) for d in docs_for_t2m]\n",
    "depr_mtids = [(str(d.material_id), [str(x) for x in d.task_ids]) for d in depr_docs_for_t2m]\n",
    "\n",
    "# keep only task_ids from (initial) ids.\n",
    "sids = set(ids)\n",
    "redused_mtids = [(m, [x for x in t if x in sids]) for m, t in mtids]\n",
    "redused_depr_mtids = [(m, [x for x in t if x in sids]) for m, t in depr_mtids]\n",
    "\n",
    "# flatten\n",
    "all_tids = []\n",
    "for m, t in redused_mtids:\n",
    "    all_tids += t\n",
    "for m, t in redused_depr_mtids:\n",
    "    all_tids += t\n",
    "print(len(get_duplicates_set(all_tids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondence between tids and mids strictly obeys the law that there is only one mid for the given tid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with (initial) ids\n",
    "\n",
    "# create map task_id -> material_id\n",
    "t2m = dict()\n",
    "for m, t in mtids:\n",
    "    for x in t:\n",
    "        t2m[x] = m\n",
    "for m, t in depr_mtids:\n",
    "    for x in t:\n",
    "        t2m[x] = m\n",
    "found = [x for x in ids if x in t2m]\n",
    "not_found = [x for x in ids if x not in t2m]\n",
    "venn(found=found, not_found=not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set theoretical image of ids after t2m\n",
    "img = [t2m[x] for x in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(img)),len(get_duplicates_list(img)),len(get_duplicates_set(img)))\n",
    "venn(img=img, ids=ids)\n",
    "# => Actual number of duplicates (data leak) in article implementation could be about 100 ids (~0.2%)\n",
    "# (~800 and 1.8% in previous version of db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset reimplementation\n",
    "Creating dataset with data leak, then without. Checking the difference in training results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for individual files\n",
    "# def save_structure_to_cif(structure, output_file):\n",
    "#     with open(output_file, \"w\") as f:\n",
    "#         cif_writer = CifWriter(structure)\n",
    "#         cif_writer.write_file(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving utility\n",
    "basedir = \"./data/root/data/\"\n",
    "cifs_file = \"./data/root/data/cifs.bin\"\n",
    "props_file = \"./data/root/data/props.bin\"\n",
    "t2m_file = \"./data/root/data/t2m.bin\"\n",
    "\n",
    "def save_to_bin(data: dict, output_file):\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(mp.packb(data,option=mp.OPT_SERIALIZE_NUMPY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_to_bin(t2m, t2m_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading functionality\n",
    "fields = [\n",
    "    \"energy_per_atom\",\n",
    "    \"formation_energy_per_atom\",\n",
    "    \"band_gap\",\n",
    "    \"efermi\",\n",
    "    \"shear_modulus\",  # \"k_voigt\", \"k_reuss\", \"k_vrh\", see https://docs.materialsproject.org/methodology/materials-methodology/elasticity/\n",
    "    \"bulk_modulus\",  # \"g_voigt\",\"g_reuss\", \"g_vrh\"\n",
    "    \"homogeneous_poisson\",\n",
    "]\n",
    "\n",
    "\n",
    "def download_by_material_ids(mids):\n",
    "    with MPRester(api_key) as mpr:\n",
    "        docs = [\n",
    "            d\n",
    "            for k in range(0, len(mids), filter_const)\n",
    "            for d in mpr.materials.summary.search(\n",
    "                material_ids=mids[k : k + filter_const],\n",
    "                fields=fields + [\"structure\", \"material_id\"],\n",
    "            )\n",
    "        ]\n",
    "        depr_docs = [\n",
    "            d\n",
    "            for k in range(0, len(mids), filter_const)\n",
    "            for d in mpr.materials.summary.search(\n",
    "                material_ids=mids[k : k + filter_const],\n",
    "                fields=fields + [\"structure\", \"material_id\"],\n",
    "                deprecated=True,\n",
    "            )\n",
    "        ]\n",
    "    all_docs = depr_docs + docs\n",
    "    return all_docs\n",
    "\n",
    "\n",
    "def save_docs_as_bin(docs, prefix=None):\n",
    "    props = dict()\n",
    "    cifs = dict()\n",
    "    for d in docs:\n",
    "        mid = str(d.material_id)\n",
    "        # structures\n",
    "        cifs[mid] = d.structure.as_dict()\n",
    "\n",
    "        # properties\n",
    "        dump = d.model_dump(include=fields)\n",
    "        # translate shear_modulus and bulk_modulus to k_ and g_ in case they exist\n",
    "        modulus_types = [\"voigt\", \"reuss\", \"vrh\"]\n",
    "        if \"shear_modulus\" in dump and dump[\"shear_modulus\"] is not None:\n",
    "            for mt in modulus_types:\n",
    "                dump[\"k_\" + mt] = dump[\"shear_modulus\"][mt]\n",
    "            dump.pop(\"shear_modulus\")\n",
    "        if \"bulk_modulus\" in dump and dump[\"bulk_modulus\"] is not None:\n",
    "            for mt in modulus_types:\n",
    "                dump[\"g_\" + mt] = dump[\"bulk_modulus\"][mt]\n",
    "            dump.pop(\"bulk_modulus\")\n",
    "        for moduli in [\"k_voigt\", \"k_reuss\", \"k_vrh\", \"g_voigt\", \"g_reuss\", \"g_vrh\"]:\n",
    "            if moduli in dump:\n",
    "                dump[moduli] = np.log(\n",
    "                    dump[moduli]\n",
    "                )  # training of this property is performed in log scale\n",
    "        props[mid] = dump\n",
    "    # print(cifs)\n",
    "    if prefix is not None:\n",
    "        save_to_bin(cifs, basedir+prefix+'_cifs.bin')\n",
    "        save_to_bin(props, basedir+prefix+'_props.bin')\n",
    "    else:\n",
    "        save_to_bin(cifs, cifs_file)\n",
    "        save_to_bin(props, props_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = download_by_material_ids(mids=img)\n",
    "# save_docs_as_bin(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression with zstd\n",
    "import zstandard as zstd\n",
    "\n",
    "cifs_zipfile = \"./data/root/cifs.zstd\"\n",
    "props_zipfile = \"./data/root/props.zstd\"\n",
    "\n",
    "\n",
    "def compress_all():\n",
    "    with open(cifs_file, \"rb\") as f:\n",
    "        res = zstd.compress(f.read(), level=10)\n",
    "    with open(cifs_zipfile, \"wb\") as f:\n",
    "        f.write(res)\n",
    "    with open(props_file, \"rb\") as f:\n",
    "        res = zstd.compress(f.read(), level=10)\n",
    "    with open(props_zipfile, \"wb\") as f:\n",
    "        f.write(res)\n",
    "        \n",
    "def uncompress_all():\n",
    "    with open(cifs_zipfile, \"rb\") as f:\n",
    "        res = zstd.decompress(f.read())\n",
    "    with open(cifs_file, \"wb\") as f:\n",
    "        f.write(res)\n",
    "    with open(props_zipfile, \"rb\") as f:\n",
    "        res = zstd.decompress(f.read())\n",
    "    with open(props_file, \"wb\") as f:\n",
    "        f.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress_all()\n",
    "# uncompress_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for individual files\n",
    "# propfiles = os.listdir(basedir)\n",
    "# def load_properties_from_json(file):\n",
    "#     filename = os.path.basename(file)\n",
    "#     with open(basedir + file, \"rb\") as f:\n",
    "#         properties = json.load(f)\n",
    "#         return (filename, properties)\n",
    "# propdata = dict()\n",
    "# for file in propfiles:\n",
    "#     name,prop=load_properties_from_json(file)\n",
    "#     for key in prop.keys():\n",
    "#         propdata.setdefault(key,[])\n",
    "#         propdata[key].append(prop[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nodoteve/apps/pythom/miniconda/envs/cgcnn/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/home/nodoteve/apps/pythom/miniconda/envs/cgcnn/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/home/nodoteve/apps/pythom/miniconda/envs/cgcnn/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/home/nodoteve/apps/pythom/miniconda/envs/cgcnn/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_per_atom</th>\n",
       "      <th>formation_energy_per_atom</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>efermi</th>\n",
       "      <th>homogeneous_poisson</th>\n",
       "      <th>k_voigt</th>\n",
       "      <th>k_reuss</th>\n",
       "      <th>k_vrh</th>\n",
       "      <th>g_voigt</th>\n",
       "      <th>g_reuss</th>\n",
       "      <th>g_vrh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46055.000000</td>\n",
       "      <td>46055.000000</td>\n",
       "      <td>46632.000000</td>\n",
       "      <td>46632.000000</td>\n",
       "      <td>8802.000000</td>\n",
       "      <td>8470.000000</td>\n",
       "      <td>8272.000000</td>\n",
       "      <td>8391.000000</td>\n",
       "      <td>8740.000000</td>\n",
       "      <td>8748.000000</td>\n",
       "      <td>8731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.402272</td>\n",
       "      <td>-1.703857</td>\n",
       "      <td>1.394342</td>\n",
       "      <td>2.901569</td>\n",
       "      <td>0.298029</td>\n",
       "      <td>3.706039</td>\n",
       "      <td>-inf</td>\n",
       "      <td>3.624273</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.408867</td>\n",
       "      <td>1.047019</td>\n",
       "      <td>1.659040</td>\n",
       "      <td>2.674768</td>\n",
       "      <td>2.460508</td>\n",
       "      <td>1.320703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.344982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-83.024212</td>\n",
       "      <td>-4.510049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.017281</td>\n",
       "      <td>-179.362000</td>\n",
       "      <td>-3.015935</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-2.603690</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.646992</td>\n",
       "      <td>-2.502314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084994</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.152789</td>\n",
       "      <td>2.921924</td>\n",
       "      <td>3.042139</td>\n",
       "      <td>3.897767</td>\n",
       "      <td>3.852851</td>\n",
       "      <td>3.866691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-7.329141</td>\n",
       "      <td>-1.857242</td>\n",
       "      <td>0.699550</td>\n",
       "      <td>2.640544</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>3.732202</td>\n",
       "      <td>3.596449</td>\n",
       "      <td>3.659064</td>\n",
       "      <td>4.492276</td>\n",
       "      <td>4.464562</td>\n",
       "      <td>4.477780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-5.984656</td>\n",
       "      <td>-0.746991</td>\n",
       "      <td>2.487525</td>\n",
       "      <td>4.612346</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>4.270973</td>\n",
       "      <td>4.214469</td>\n",
       "      <td>4.240405</td>\n",
       "      <td>5.009493</td>\n",
       "      <td>4.993403</td>\n",
       "      <td>5.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.310334</td>\n",
       "      <td>4.310576</td>\n",
       "      <td>16.586400</td>\n",
       "      <td>17.758767</td>\n",
       "      <td>82.881000</td>\n",
       "      <td>32.358331</td>\n",
       "      <td>8.554642</td>\n",
       "      <td>31.665184</td>\n",
       "      <td>25.044718</td>\n",
       "      <td>17.473889</td>\n",
       "      <td>24.351570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy_per_atom  formation_energy_per_atom      band_gap        efermi  \\\n",
       "count     46055.000000               46055.000000  46632.000000  46632.000000   \n",
       "mean         -9.402272                  -1.703857      1.394342      2.901569   \n",
       "std           7.408867                   1.047019      1.659040      2.674768   \n",
       "min         -83.024212                  -4.510049      0.000000    -14.017281   \n",
       "25%          -8.646992                  -2.502314      0.000000      1.084994   \n",
       "50%          -7.329141                  -1.857242      0.699550      2.640544   \n",
       "75%          -5.984656                  -0.746991      2.487525      4.612346   \n",
       "max          -0.310334                   4.310576     16.586400     17.758767   \n",
       "\n",
       "       homogeneous_poisson      k_voigt      k_reuss        k_vrh  \\\n",
       "count          8802.000000  8470.000000  8272.000000  8391.000000   \n",
       "mean              0.298029     3.706039         -inf     3.624273   \n",
       "std               2.460508     1.320703          NaN     1.344982   \n",
       "min            -179.362000    -3.015935         -inf    -2.603690   \n",
       "25%               0.250000     3.152789     2.921924     3.042139   \n",
       "50%               0.294000     3.732202     3.596449     3.659064   \n",
       "75%               0.339000     4.270973     4.214469     4.240405   \n",
       "max              82.881000    32.358331     8.554642    31.665184   \n",
       "\n",
       "           g_voigt      g_reuss        g_vrh  \n",
       "count  8740.000000  8748.000000  8731.000000  \n",
       "mean          -inf         -inf         -inf  \n",
       "std            NaN          NaN          NaN  \n",
       "min           -inf         -inf         -inf  \n",
       "25%       3.897767     3.852851     3.866691  \n",
       "50%       4.492276     4.464562     4.477780  \n",
       "75%       5.009493     4.993403     5.002230  \n",
       "max      25.044718    17.473889    24.351570  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data statistics for current dataset\n",
    "import ormsgpack as mp\n",
    "\n",
    "def load_from_bin(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        properties = mp.unpackb(f.read())\n",
    "        return properties\n",
    "\n",
    "\n",
    "full_df = pd.DataFrame(load_from_bin(props_file)).transpose()\n",
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on all properties for full_df dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import run\n",
    "\n",
    "reference_csv = {\n",
    "    \"mp-ids-3402.csv\": [\n",
    "        \"k_voigt\",\n",
    "        # \"k_reuss\",\n",
    "        # \"k_vrh\",\n",
    "        # \"g_voigt\",\n",
    "        # \"g_reuss\",\n",
    "        # \"g_vrh\",\n",
    "        # \"homogeneous_poisson\",\n",
    "    ],\n",
    "    # \"mp-ids-27430.csv\": [\"band_gap\"],\n",
    "    # \"mp-ids-46744.csv\": [\"energy_per_atom\", \"formation_energy_per_atom\", \"efermi\"],\n",
    "}\n",
    "\n",
    "\n",
    "def set_property_to_ids(df: pd.DataFrame, property: str):\n",
    "    # nids = df[property].isna()\n",
    "    df[property].dropna().to_csv(\n",
    "        \"./data/root/data/id_prop.csv\", index=True, header=False\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_csv(csv: str, df: pd.DataFrame, prop: str):\n",
    "    set_property_to_ids(df, prop)\n",
    "\n",
    "\n",
    "t2m = load_from_bin(t2m_file)\n",
    "\n",
    "def get_df_for_csv(csv:str):\n",
    "    global t2m, full_df\n",
    "\n",
    "    ids = pd.read_csv(\"./data/material-data/\" + csv)\n",
    "    ids = [list(ids)[0]]+list(ids.iloc[:, 0])\n",
    "    new_df = pd.DataFrame()\n",
    "    idx = full_df.index\n",
    "    ms =[t2m[t] for t in ids if t2m[t] in idx]\n",
    "    new_df = full_df.loc[ms]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nodoteve/apps/pythom/miniconda/envs/cgcnn/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_per_atom</th>\n",
       "      <th>formation_energy_per_atom</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>efermi</th>\n",
       "      <th>homogeneous_poisson</th>\n",
       "      <th>k_voigt</th>\n",
       "      <th>k_reuss</th>\n",
       "      <th>k_vrh</th>\n",
       "      <th>g_voigt</th>\n",
       "      <th>g_reuss</th>\n",
       "      <th>g_vrh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3402.000000</td>\n",
       "      <td>3402.000000</td>\n",
       "      <td>3402.000000</td>\n",
       "      <td>3402.000000</td>\n",
       "      <td>2950.000000</td>\n",
       "      <td>2927.000000</td>\n",
       "      <td>2903.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2934.000000</td>\n",
       "      <td>2931.000000</td>\n",
       "      <td>2929.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-12.147303</td>\n",
       "      <td>-0.952483</td>\n",
       "      <td>0.678811</td>\n",
       "      <td>4.814247</td>\n",
       "      <td>0.282928</td>\n",
       "      <td>3.927095</td>\n",
       "      <td>-inf</td>\n",
       "      <td>3.858064</td>\n",
       "      <td>4.574724</td>\n",
       "      <td>4.493641</td>\n",
       "      <td>4.548808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.521122</td>\n",
       "      <td>0.956267</td>\n",
       "      <td>1.353280</td>\n",
       "      <td>2.744502</td>\n",
       "      <td>0.136696</td>\n",
       "      <td>1.300404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.291339</td>\n",
       "      <td>0.985032</td>\n",
       "      <td>0.875161</td>\n",
       "      <td>0.982597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-56.285134</td>\n",
       "      <td>-4.223837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.654093</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-0.689155</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.309333</td>\n",
       "      <td>1.525839</td>\n",
       "      <td>-0.507498</td>\n",
       "      <td>1.489753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-15.073407</td>\n",
       "      <td>-1.289773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.001713</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>3.374477</td>\n",
       "      <td>3.185918</td>\n",
       "      <td>3.291057</td>\n",
       "      <td>4.054373</td>\n",
       "      <td>4.017881</td>\n",
       "      <td>4.034152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.434996</td>\n",
       "      <td>-0.592026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.175226</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>3.978017</td>\n",
       "      <td>3.871034</td>\n",
       "      <td>3.919753</td>\n",
       "      <td>4.705061</td>\n",
       "      <td>4.680305</td>\n",
       "      <td>4.690549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-6.321394</td>\n",
       "      <td>-0.302318</td>\n",
       "      <td>0.742900</td>\n",
       "      <td>6.931447</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>4.461213</td>\n",
       "      <td>4.390522</td>\n",
       "      <td>4.420929</td>\n",
       "      <td>5.144671</td>\n",
       "      <td>5.132065</td>\n",
       "      <td>5.136263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.858596</td>\n",
       "      <td>2.756673</td>\n",
       "      <td>8.716100</td>\n",
       "      <td>12.401693</td>\n",
       "      <td>4.017000</td>\n",
       "      <td>32.358331</td>\n",
       "      <td>6.520957</td>\n",
       "      <td>31.665184</td>\n",
       "      <td>18.955657</td>\n",
       "      <td>14.689042</td>\n",
       "      <td>18.262511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy_per_atom  formation_energy_per_atom     band_gap       efermi  \\\n",
       "count      3402.000000                3402.000000  3402.000000  3402.000000   \n",
       "mean        -12.147303                  -0.952483     0.678811     4.814247   \n",
       "std           9.521122                   0.956267     1.353280     2.744502   \n",
       "min         -56.285134                  -4.223837     0.000000    -4.654093   \n",
       "25%         -15.073407                  -1.289773     0.000000     3.001713   \n",
       "50%          -8.434996                  -0.592026     0.000000     5.175226   \n",
       "75%          -6.321394                  -0.302318     0.742900     6.931447   \n",
       "max          -0.858596                   2.756673     8.716100    12.401693   \n",
       "\n",
       "       homogeneous_poisson      k_voigt      k_reuss        k_vrh  \\\n",
       "count          2950.000000  2927.000000  2903.000000  2918.000000   \n",
       "mean              0.282928     3.927095         -inf     3.858064   \n",
       "std               0.136696     1.300404          NaN     1.291339   \n",
       "min              -3.500000    -0.689155         -inf    -1.309333   \n",
       "25%               0.242000     3.374477     3.185918     3.291057   \n",
       "50%               0.283000     3.978017     3.871034     3.919753   \n",
       "75%               0.324000     4.461213     4.390522     4.420929   \n",
       "max               4.017000    32.358331     6.520957    31.665184   \n",
       "\n",
       "           g_voigt      g_reuss        g_vrh  \n",
       "count  2934.000000  2931.000000  2929.000000  \n",
       "mean      4.574724     4.493641     4.548808  \n",
       "std       0.985032     0.875161     0.982597  \n",
       "min       1.525839    -0.507498     1.489753  \n",
       "25%       4.054373     4.017881     4.034152  \n",
       "50%       4.705061     4.680305     4.690549  \n",
       "75%       5.144671     5.132065     5.136263  \n",
       "max      18.955657    14.689042    18.262511  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_for_csv('mp-ids-3402.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "env_name = \"cgcnn\"\n",
    "def run_process():\n",
    "    res = run(\n",
    "        f\"conda run -n {env_name} python main.py {basedir}\",\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        shell=True,\n",
    "    )\n",
    "    return res.stdout.split(\"** MAE \")[-1].replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k_voigt': '0.388'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train each parameter once\n",
    "# with deterministic learning\n",
    "# ! conda env config vars set \n",
    "import shutil as st\n",
    "maedict = dict()\n",
    "for csv in reference_csv.keys():\n",
    "    df = get_df_for_csv(csv)\n",
    "\n",
    "    for prop in reference_csv[csv]:\n",
    "        prepare_csv(csv, df, prop)\n",
    "        mae = run_process()\n",
    "        try:\n",
    "            st.move(\"checkpoint.pth.tar\", \"./trained/\" + prop + \"_check.pth.tar\")\n",
    "            st.move(\"model_best.pth.tar\", \"./trained/\" + prop + \"_best.pth.tar\")\n",
    "            st.move(\"test_results.csv\", \"./trained/\" + prop + \"_results.csv\")\n",
    "        except:\n",
    "            pass\n",
    "        maedict[prop] = mae\n",
    "maedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train without data leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_csv_no_leak(csv: str, df: pd.DataFrame, prop: str):\n",
    "    part_df=df[prop].dropna()\n",
    "    part_df=part_df.groupby(part_df.index).first()\n",
    "    part_df.to_csv(\"./data/root/data/id_prop.csv\", index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k_voigt': '0.407'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train each parameter once\n",
    "import shutil as st\n",
    "maedict = dict()\n",
    "for csv in reference_csv.keys():\n",
    "    df = get_df_for_csv(csv)\n",
    "\n",
    "    for prop in reference_csv[csv]:\n",
    "        prepare_csv_no_leak(csv, df, prop)\n",
    "        mae = run_process()\n",
    "        try:\n",
    "            st.move(\"checkpoint.pth.tar\", \"./trained/\" + prop + \"_check.pth.tar\")\n",
    "            st.move(\"model_best.pth.tar\", \"./trained/\" + prop + \"_best.pth.tar\")\n",
    "            st.move(\"test_results.csv\", \"./trained/\" + prop + \"_results.csv\")\n",
    "        except:\n",
    "            pass\n",
    "        maedict[prop] = mae\n",
    "        # with open(\"train_outputs.json\", \"w\") as f:\n",
    "        #     json.dump(resdict, f)\n",
    "        # pd.DataFrame(maedict, index=['MAE']).transpose().to_csv('train_maes.csv')\n",
    "maedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On recent MT db version for all ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (undeprecated cifs and props)\n",
    "fields = [\n",
    "    \"energy_per_atom\",\n",
    "    \"formation_energy_per_atom\",\n",
    "    \"band_gap\",\n",
    "    \"efermi\",\n",
    "    \"k_voigt\",\n",
    "    \"k_reuss\",\n",
    "    \"k_vrh\",\n",
    "    \"g_voigt\",\n",
    "    \"g_reuss\",\n",
    "    \"g_vrh\",\n",
    "    \"homogeneous_poisson\",\n",
    "]\n",
    "all_props_file = \"./data/root/data/db_props.bin\"\n",
    "all_cifs_file = \"./data/root/data/db_cifs.bin\"\n",
    "def download_full_mpdb_undeprecated():\n",
    "    with MPRester(api_key) as mpr:\n",
    "        docs = [\n",
    "            d\n",
    "            for d in mpr.materials.summary.search(\n",
    "                fields=fields + [\"structure\", \"material_id\"],\n",
    "            )\n",
    "        ]\n",
    "    return docs\n",
    "\n",
    "# download_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'shear_modulus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# all_docs =  download_full_mpdb_undeprecated()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msave_docs_as_bin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 51\u001b[0m, in \u001b[0;36msave_docs_as_bin\u001b[0;34m(docs, prefix)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mt \u001b[38;5;129;01min\u001b[39;00m modulus_types:\n\u001b[1;32m     50\u001b[0m         dump[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m mt] \u001b[38;5;241m=\u001b[39m dump[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshear_modulus\u001b[39m\u001b[38;5;124m\"\u001b[39m][mt]\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdump\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear_modulus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbulk_modulus\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dump \u001b[38;5;129;01mand\u001b[39;00m dump[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbulk_modulus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mt \u001b[38;5;129;01min\u001b[39;00m modulus_types:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shear_modulus'"
     ]
    }
   ],
   "source": [
    "# all_docs =  download_full_mpdb_undeprecated()\n",
    "save_docs_as_bin(all_docs,'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_props_file_zstd = \"./data/root/db_props.zstd\"\n",
    "all_cifs_file_zstd = \"./data/root/db_cifs.zstd\"\n",
    "\n",
    "\n",
    "def compress_all():\n",
    "    with open(cifs_file, \"rb\") as f:\n",
    "        res = zstd.compress(f.read(), level=10)\n",
    "    with open(all_props_file_zstd, \"wb\") as f:\n",
    "        f.write(res)\n",
    "    with open(props_file, \"rb\") as f:\n",
    "        res = zstd.compress(f.read(), level=10)\n",
    "    with open(all_props_file_zstd, \"wb\") as f:\n",
    "        f.write(res)\n",
    "\n",
    "compress_all()\n",
    "\n",
    "def uncompress_all():\n",
    "    with open(all_cifs_file_zstd, \"rb\") as f:\n",
    "        res = zstd.decompress(f.read())\n",
    "    with open(cifs_file, \"wb\") as f:\n",
    "        f.write(res)\n",
    "    with open(all_props_file_zstd, \"rb\") as f:\n",
    "        res = zstd.decompress(f.read())\n",
    "    with open(props_file, \"wb\") as f:\n",
    "        f.write(res)\n",
    "\n",
    "\n",
    "# uncompress_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DF\n",
    "def load_from_bin(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        properties = mp.unpackb(f.read())\n",
    "        return properties\n",
    "    return None\n",
    "\n",
    "full_df = pd.DataFrame(load_from_bin(all_props_file)).transpose()\n",
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_property_to_ids(df: pd.DataFrame, prop: str):\n",
    "    part_df = df[prop].dropna()\n",
    "    print(part_df.head())\n",
    "    part_df = part_df.groupby(part_df.index).first()\n",
    "    print(part_df.head())\n",
    "    part_df.to_csv(\"./data/root/data/id_prop.csv\", index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prop in fields:\n",
    "#     set_property_to_ids(full_df, prop)\n",
    "#     res = run(\n",
    "#         \"conda run -n cgcnn2 python main.py --train-ratio 0.6 --val-ratio 0.2 --test-ratio 0.2 ./data/root/data/\",\n",
    "#         capture_output=True,\n",
    "#         text=True,\n",
    "#         shell=True,\n",
    "#     )\n",
    "#     resdict[prop] = res.stdout\n",
    "#     maedict[prop] = resdict[prop].split(\"** MAE \")[-1].replace('\\n','')\n",
    "    \n",
    "#     print(prop, maedict[prop])\n",
    "\n",
    "#     st.move(\"checkpoint.pth.tar\", \"./trained/\" + prop + \"_check.pth.tar\")\n",
    "#     st.move(\"model_best.pth.tar\", \"./trained/\" + prop + \"_best.pth.tar\")\n",
    "#     st.move(\"test_results.csv\", \"./trained/\" + prop + \"_results.csv\")\n",
    "        \n",
    "# with open(\"train_outputs.json\", \"w\") as f:\n",
    "#     json.dump(resdict, f)\n",
    "# pd.DataFrame(maedict).to_csv('train_maes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort out crystals with warnings:\n",
    "from pymatgen.core import Structure\n",
    "from cgcnn.data import get_all_neighbors\n",
    "ill = set()\n",
    "with open('./data/root/data/db_cifs.bin','rb') as f:\n",
    "    cifs = mp.unpackb(f.read())\n",
    "    for i, row in full_df.iterrows():\n",
    "        crystal = Structure.from_dict(cifs[i])\n",
    "        all_nbrs = get_all_neighbors(crystal, r=8, include_index=True)\n",
    "        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n",
    "        max_num_nbr=12\n",
    "        for nbr in all_nbrs:\n",
    "            if len(nbr) < max_num_nbr:\n",
    "                ill.add(i)\n",
    "non_ill_df = full_df.drop(list(ill), axis='index')\n",
    "set_property_to_ids(non_ill_df, 'formation_energy_per_atom')\n",
    "non_ill_df.to_csv('non_ill_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_property_to_ids(non_ill_df, 'energy_per_atom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in fields:\n",
    "    set_property_to_ids(non_ill_df, prop)\n",
    "    res = run(\n",
    "        \"conda run -n cgcnn2 python main.py --train-ratio 0.6 --val-ratio 0.2 --test-ratio 0.2 ./data/root/data/\",\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        shell=True,\n",
    "    )\n",
    "    resdict[prop] = res.stdout\n",
    "    maedict[prop] = resdict[prop].split(\"** MAE \")[-1].replace('\\n','')\n",
    "    \n",
    "    print(prop, maedict[prop])\n",
    "\n",
    "    st.move(\"checkpoint.pth.tar\", \"./trained/\" + prop + \"_check.pth.tar\")\n",
    "    st.move(\"model_best.pth.tar\", \"./trained/\" + prop + \"_best.pth.tar\")\n",
    "    st.move(\"test_results.csv\", \"./trained/\" + prop + \"_results.csv\")\n",
    "        \n",
    "with open(\"train_outputs.json\", \"w\") as f:\n",
    "    json.dump(resdict, f)\n",
    "pd.DataFrame(maedict).to_csv('train_maes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1509f755d693feea69328e7bc671a76db594dddf9693d82a53ea384d1f791343"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
